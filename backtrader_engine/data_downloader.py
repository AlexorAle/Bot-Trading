#!/usr/bin/env python3
"""
Script para descargar datos hist√≥ricos de criptomonedas desde Binance usando ccxt.
Compatible con Backtrader y el portfolio_engine.py existente.

Autor: Cursor IDE + ChatGPT
Fecha: 2025-01-14
"""

import ccxt
import pandas as pd
import os
import time
from datetime import datetime, timedelta
import logging

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_download.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def download_crypto_data(symbol, timeframe='15m', since='2020-01-01', data_dir='backtrader_engine/data/'):
    """
    Descarga datos hist√≥ricos de Binance con ccxt, los formatea para Backtrader y guarda en CSV.
    
    Args:
        symbol (str): Par de trading, ej. 'ETH/USDT' o 'SOL/USDT'
        timeframe (str): Timeframe, ej. '1m', '15m', '1h', '1d'
        since (str): Fecha de inicio en formato YYYY-MM-DD
        data_dir (str): Directorio para guardar CSVs
    
    Returns:
        str: Ruta del archivo CSV generado
    """
    logger.info(f"üöÄ Iniciando descarga de {symbol} - {timeframe} desde {since}")
    
    try:
        # Inicializar exchange (no necesita API keys para datos p√∫blicos)
        exchange = ccxt.binance()
        logger.info(f"‚úÖ Exchange Binance inicializado correctamente")
        
        # Convertir fecha a timestamp en milisegundos
        since_ms = exchange.parse8601(since + 'T00:00:00Z')
        logger.info(f"üìÖ Timestamp de inicio: {since_ms} ({since})")
        
        # Crear directorio si no existe
        os.makedirs(data_dir, exist_ok=True)
        
        # Nombre del archivo
        filename = f"{data_dir}{symbol.replace('/', '')}_{timeframe}.csv"
        logger.info(f"üìÅ Archivo destino: {filename}")
        
        # Descargar datos con paginaci√≥n
        all_ohlcv = []
        chunk_count = 0
        total_bars = 0
        
        logger.info(f"üìä Iniciando descarga paginada...")
        
        while True:
            try:
                # Fetch con l√≠mite de 1000 barras por llamada
                ohlcv = exchange.fetch_ohlcv(symbol, timeframe, since=since_ms, limit=1000)
                
                if not ohlcv:
                    logger.info(f"‚úÖ No hay m√°s datos disponibles")
                    break
                
                all_ohlcv.extend(ohlcv)
                chunk_count += 1
                total_bars = len(all_ohlcv)
                
                # Actualizar timestamp para siguiente chunk
                since_ms = ohlcv[-1][0] + 1
                
                logger.info(f"üì¶ Chunk {chunk_count}: {len(ohlcv)} barras (Total: {total_bars})")
                
                # Verificar si llegamos al presente
                if since_ms >= exchange.milliseconds():
                    logger.info(f"‚úÖ Llegamos al presente, finalizando descarga")
                    break
                
                # Rate limiting: pausa peque√±a entre llamadas
                time.sleep(0.1)
                
            except Exception as e:
                logger.error(f"‚ùå Error en chunk {chunk_count}: {e}")
                time.sleep(1)  # Pausa m√°s larga en caso de error
                continue
        
        if not all_ohlcv:
            logger.error(f"‚ùå No se obtuvieron datos para {symbol}")
            return None
        
        # Convertir a DataFrame en formato Backtrader
        logger.info(f"üîÑ Convirtiendo {total_bars} barras a DataFrame...")
        df = pd.DataFrame(all_ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        
        # Convertir timestamp a datetime
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        
        # Validar datos
        logger.info(f"üîç Validando datos...")
        logger.info(f"   - Rango de fechas: {df['timestamp'].min()} a {df['timestamp'].max()}")
        logger.info(f"   - Precio inicial: ${df['close'].iloc[0]:.2f}")
        logger.info(f"   - Precio final: ${df['close'].iloc[-1]:.2f}")
        logger.info(f"   - Volumen promedio: {df['volume'].mean():.0f}")
        
        # Verificar datos faltantes o inv√°lidos
        null_count = df.isnull().sum().sum()
        if null_count > 0:
            logger.warning(f"‚ö†Ô∏è  Encontrados {null_count} valores nulos")
        
        # Verificar precios no positivos
        invalid_prices = (df[['open', 'high', 'low', 'close']] <= 0).any().any()
        if invalid_prices:
            logger.warning(f"‚ö†Ô∏è  Encontrados precios no positivos")
        
        # Guardar CSV
        logger.info(f"üíæ Guardando CSV en {filename}...")
        df.to_csv(filename, index=False)
        
        # Verificar archivo guardado
        file_size = os.path.getsize(filename)
        logger.info(f"‚úÖ Archivo guardado: {file_size:,} bytes")
        
        logger.info(f"üéâ Descarga completada: {symbol} - {total_bars} barras en {filename}")
        return filename
        
    except Exception as e:
        logger.error(f"‚ùå Error cr√≠tico descargando {symbol}: {e}")
        return None

def download_multiple_symbols(symbols, timeframe='15m', since='2020-01-01', data_dir='backtrader_engine/data/'):
    """
    Descarga m√∫ltiples s√≠mbolos secuencialmente.
    
    Args:
        symbols (list): Lista de pares de trading
        timeframe (str): Timeframe
        since (str): Fecha de inicio
        data_dir (str): Directorio destino
    
    Returns:
        dict: Diccionario con resultados de cada descarga
    """
    logger.info(f"üöÄ Iniciando descarga m√∫ltiple: {symbols}")
    
    results = {}
    start_time = datetime.now()
    
    for i, symbol in enumerate(symbols, 1):
        logger.info(f"\n{'='*60}")
        logger.info(f"üìä Descargando {symbol} ({i}/{len(symbols)})")
        logger.info(f"{'='*60}")
        
        result = download_crypto_data(symbol, timeframe, since, data_dir)
        results[symbol] = result
        
        if result:
            logger.info(f"‚úÖ {symbol}: √âXITO")
        else:
            logger.error(f"‚ùå {symbol}: FALLO")
        
        # Pausa entre descargas para evitar rate limiting
        if i < len(symbols):
            logger.info(f"‚è≥ Pausa de 2 segundos antes de siguiente descarga...")
            time.sleep(2)
    
    end_time = datetime.now()
    duration = end_time - start_time
    
    logger.info(f"\n{'='*60}")
    logger.info(f"üèÅ RESUMEN DE DESCARGA M√öLTIPLE")
    logger.info(f"{'='*60}")
    logger.info(f"‚è±Ô∏è  Duraci√≥n total: {duration}")
    logger.info(f"üìä S√≠mbolos procesados: {len(symbols)}")
    
    successful = sum(1 for result in results.values() if result)
    failed = len(symbols) - successful
    
    logger.info(f"‚úÖ Exitosos: {successful}")
    logger.info(f"‚ùå Fallidos: {failed}")
    
    for symbol, result in results.items():
        status = "‚úÖ" if result else "‚ùå"
        logger.info(f"   {status} {symbol}: {result or 'FALLO'}")
    
    return results

def main():
    """Funci√≥n principal para descarga de ETH y SOL (6 meses)"""
    logger.info(f"üöÄ INICIANDO DESCARGA DE DATOS HIST√ìRICOS")
    logger.info(f"üìÖ Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Calcular fecha de inicio (6 meses atr√°s)
    end_date = datetime.now()
    start_date = end_date - timedelta(days=180)  # ~6 meses
    since_str = start_date.strftime('%Y-%m-%d')
    
    logger.info(f"üìÖ Per√≠odo: {since_str} a {end_date.strftime('%Y-%m-%d')} (~6 meses)")
    
    # S√≠mbolos a descargar
    symbols = ['ETH/USDT', 'SOL/USDT']
    timeframe = '15m'
    data_dir = 'data/'
    
    # Ejecutar descarga m√∫ltiple
    results = download_multiple_symbols(symbols, timeframe, since_str, data_dir)
    
    # Verificar archivos generados
    logger.info(f"\n{'='*60}")
    logger.info(f"üîç VERIFICACI√ìN DE ARCHIVOS GENERADOS")
    logger.info(f"{'='*60}")
    
    for symbol in symbols:
        filename = f"{data_dir}{symbol.replace('/', '')}_{timeframe}.csv"
        if os.path.exists(filename):
            file_size = os.path.getsize(filename)
            logger.info(f"‚úÖ {filename}: {file_size:,} bytes")
            
            # Leer primeras l√≠neas para verificar formato
            try:
                df = pd.read_csv(filename, nrows=5)
                logger.info(f"   üìä Columnas: {list(df.columns)}")
                logger.info(f"   üìÖ Primera fecha: {df['timestamp'].iloc[0]}")
                logger.info(f"   üí∞ Primer precio: ${df['close'].iloc[0]:.2f}")
            except Exception as e:
                logger.error(f"   ‚ùå Error leyendo archivo: {e}")
        else:
            logger.error(f"‚ùå {filename}: NO ENCONTRADO")
    
    logger.info(f"\nüéâ DESCARGA COMPLETADA")
    logger.info(f"üìÅ Archivos guardados en: {data_dir}")
    logger.info(f"üìã Log completo en: data_download.log")

if __name__ == "__main__":
    main()
