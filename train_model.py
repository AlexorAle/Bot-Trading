#!/usr/bin/env python3
"""
Script para entrenar el modelo ML manualmente con m√°s datos hist√≥ricos
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from data.data_fetcher import DataFetcher
from processing.ml_model import MLModel
from processing.kalman_filter import KalmanFilter
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import logging
import time

# Configurar logging
logging.basicConfig(level=logging.INFO)
log = logging.getLogger(__name__)

def _validate_data_quality(data):
    """Validar calidad de datos para entrenamiento"""
    if data is None or data.empty:
        return False
    
    # Verificar columnas requeridas
    required_columns = ['open', 'high', 'low', 'close', 'volume']
    if not all(col in data.columns for col in required_columns):
        return False
    
    # Verificar valores nulos
    if data[required_columns].isnull().any().any():
        return False
    
    # Verificar valores negativos en precios
    price_columns = ['open', 'high', 'low', 'close']
    if (data[price_columns] <= 0).any().any():
        return False
    
    # Verificar valores negativos en volumen
    if (data['volume'] < 0).any():
        return False
    
    # Verificar datos suficientes
    if len(data) < 10:
        return False
    
    return True

def train_model_manually():
    """Entrena el modelo ML con datos hist√≥ricos extensos"""
    
    print("üöÄ Iniciando entrenamiento manual del modelo...")
    
    # 1. Obtener m√°s datos hist√≥ricos con manejo robusto de errores
    print("üìä Obteniendo datos hist√≥ricos extensos...")
    fetcher = DataFetcher()
    
    # Obtener datos de los √∫ltimos 7 d√≠as (m√°s datos = mejor entrenamiento)
    all_data = []
    max_retries = 3
    retry_delay = 2
    
    for days_back in range(7, 0, -1):
        success = False
        for attempt in range(max_retries):
            try:
                # Simular obtenci√≥n de datos de d√≠as anteriores
                data = fetcher.fetch_data()
                if data is not None and not data.empty:
                    # Validar calidad de datos
                    if _validate_data_quality(data):
                        all_data.append(data)
                        print(f"‚úÖ Datos del d√≠a {days_back}: {len(data)} registros")
                        success = True
                        break
                    else:
                        print(f"‚ö†Ô∏è Datos del d√≠a {days_back} no pasaron validaci√≥n, reintentando...")
                else:
                    print(f"‚ö†Ô∏è Datos vac√≠os del d√≠a {days_back}, reintentando...")
            except ConnectionError as e:
                print(f"üîå Error de conexi√≥n d√≠a {days_back}, intento {attempt + 1}: {e}")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay * (attempt + 1))
            except Exception as e:
                print(f"‚ùå Error inesperado d√≠a {days_back}, intento {attempt + 1}: {e}")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
        
        if not success:
            print(f"‚ùå No se pudieron obtener datos del d√≠a {days_back} despu√©s de {max_retries} intentos")
    
    if not all_data:
        print("‚ùå No se pudieron obtener datos para entrenamiento")
        return False
    
    combined_data = pd.concat(all_data).sort_index()
    print(f"üìà Total de datos para entrenamiento: {len(combined_data)} registros")
    print(f"üìÖ Rango: {combined_data.index.min()} a {combined_data.index.max()}")
    
    # 2. Aplicar filtro Kalman
    print("üîß Aplicando filtro Kalman...")
    kalman_filter = KalmanFilter()
    filtered_data = kalman_filter.apply_filter(combined_data)
    
    if filtered_data is None or filtered_data.empty:
        print("‚ùå Error aplicando filtro Kalman")
        return False
    
    # 3. Entrenar modelo ML
    print("ü§ñ Entrenando modelo Random Forest...")
    ml_model = MLModel()
    
    print(f"üìä Datos para entrenamiento: {len(filtered_data)} registros")
    print(f"üìä Columnas disponibles: {list(filtered_data.columns)}")
    
    # Entrenar el modelo (el m√©todo train maneja todo internamente)
    result = ml_model.train(filtered_data)
    success = result.get('success', False)
    
    if success:
        print("‚úÖ Modelo entrenado exitosamente!")
        
        # 4. Probar predicciones con m√©tricas extendidas
        print("üß™ Probando predicciones y calculando m√©tricas...")
        
        # Probar predicciones en muestra de prueba
        test_sample = filtered_data.tail(50)  # Usar m√°s datos para prueba
        predictions = ml_model.predict(test_sample)
        
        if predictions is not None:
            print(f"‚úÖ Predicciones generadas exitosamente")
            print(f"üìä Predicci√≥n: {'SUBA' if predictions['prediction'] == 1 else 'BAJA'}")
            print(f"üìä Probabilidad: {predictions['probability']:.3f}")
            print(f"üìä Confianza: {predictions['confidence']:.3f}")
            
            # Calcular m√©tricas adicionales si tenemos datos suficientes
            if len(filtered_data) > 100:
                print("üìà Calculando m√©tricas de validaci√≥n cruzada...")
                try:
                    # Preparar datos para validaci√≥n cruzada
                    features_df = ml_model.prepare_features(filtered_data)
                    target = ml_model.create_target(features_df)
                    
                    # Seleccionar caracter√≠sticas
                    exclude_cols = ['timestamp', 'target', 'close', 'open', 'high', 'low']
                    feature_cols = [col for col in features_df.columns if col not in exclude_cols]
                    X = features_df[feature_cols]
                    y = target
                    
                    # Remover NaN
                    mask = ~(X.isna().any(axis=1) | y.isna())
                    X = X[mask]
                    y = y[mask]
                    
                    if len(X) > 50:  # Datos suficientes para CV
                        # Validaci√≥n cruzada
                        cv_scores = cross_val_score(ml_model.model, X, y, cv=5, scoring='accuracy')
                        print(f"üìä Validaci√≥n cruzada (5-fold): {cv_scores.mean():.3f} ¬± {cv_scores.std() * 2:.3f}")
                        
                        # M√©tricas adicionales
                        y_pred = ml_model.model.predict(X)
                        precision = precision_score(y, y_pred, average='weighted')
                        recall = recall_score(y, y_pred, average='weighted')
                        f1 = f1_score(y, y_pred, average='weighted')
                        
                        print(f"üìä Precisi√≥n: {precision:.3f}")
                        print(f"üìä Recall: {recall:.3f}")
                        print(f"üìä F1-Score: {f1:.3f}")
                    else:
                        print("‚ö†Ô∏è Datos insuficientes para validaci√≥n cruzada")
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è Error calculando m√©tricas: {e}")
        else:
            print("‚ö†Ô∏è No se pudieron generar predicciones de prueba")
        
        # 5. Guardar modelo (ya se guard√≥ autom√°ticamente durante el entrenamiento)
        print("üíæ Modelo guardado autom√°ticamente durante el entrenamiento")
        
        print("üéâ ¬°Entrenamiento completado exitosamente!")
        return True
    else:
        print("‚ùå Error entrenando el modelo")
        return False

if __name__ == "__main__":
    train_model_manually()




